{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1MGFr8iWqzGD3UzaO0-pYWOlq4e7V8B99",
      "authorship_tag": "ABX9TyMN9QDsV6/kxFrsl0SRy7NQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabsLUZ/Trabalho_Final_IA/blob/main/Melhorando_Resultados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-plot"
      ],
      "metadata": {
        "id": "i7ydchW9i4TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmMwYJWOiLZY"
      },
      "outputs": [],
      "source": [
        "# Manipulacao de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualizacao de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikitplot as skplt #teve que instalar\n",
        "\n",
        "# Machine learning \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# balanceamento\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Grid e Random Search\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# cross validate\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate, KFold \n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve #mudou\n",
        "\n",
        "# Selecao de caracteristicas e encoders\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n",
        "\n",
        "# Metricas de avaliacao\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, average_precision_score,RocCurveDisplay # versão diferente\n",
        "\n",
        "# remover warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "from  sklearn.utils.multiclass  import  unique_labels\n",
        "from sklearn.utils import check_matplotlib_support\n",
        "\n",
        "class ConfusionMatrixDisplay:\n",
        "    def __init__(self, confusion_matrix, *, display_labels=None):\n",
        "        self.confusion_matrix = confusion_matrix\n",
        "        self.display_labels = display_labels\n",
        "\n",
        "    def plot(self, *, include_values=True, cmap='Blues',\n",
        "             xticks_rotation='horizontal', values_format=None,\n",
        "             ax=None, colorbar=True):\n",
        "        \n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots()\n",
        "        else:\n",
        "            fig = ax.figure\n",
        "\n",
        "        cm = self.confusion_matrix\n",
        "        n_classes = cm.shape[0]\n",
        "        self.im_ = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        self.text_ = None\n",
        "        cmap_min, cmap_max = self.im_.cmap(0), self.im_.cmap(1.0)\n",
        "\n",
        "        if include_values:\n",
        "            self.text_ = np.empty_like(cm, dtype=object)\n",
        "\n",
        "            # print text with appropriate color depending on background\n",
        "            thresh = (cm.max() + cm.min()) / 2.0\n",
        "\n",
        "            for i, j in product(range(n_classes), range(n_classes)):\n",
        "                color = cmap_max if cm[i, j] < thresh else cmap_min\n",
        "\n",
        "                if values_format is None:\n",
        "                    text_cm = format(cm[i, j], '.2g')\n",
        "                    if cm.dtype.kind != 'f':\n",
        "                        text_d = format(cm[i, j], 'd')\n",
        "                        if len(text_d) < len(text_cm):\n",
        "                            text_cm = text_d\n",
        "                else:\n",
        "                    text_cm = format(cm[i, j], values_format)\n",
        "\n",
        "                self.text_[i, j] = ax.text(\n",
        "                    j, i, text_cm,\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=color)\n",
        "\n",
        "        if self.display_labels is None:\n",
        "            display_labels = np.arange(n_classes)\n",
        "        else:\n",
        "            display_labels = self.display_labels\n",
        "        if colorbar:\n",
        "            fig.colorbar(self.im_, ax=ax)\n",
        "        ax.set(xticks=np.arange(n_classes),\n",
        "               yticks=np.arange(n_classes),\n",
        "               xticklabels=display_labels,\n",
        "               yticklabels=display_labels,\n",
        "               ylabel=\"Valor Real\",\n",
        "               xlabel=\"Valor Predito\")\n",
        "\n",
        "        ax.set_ylim((n_classes - 0.5, -0.5))\n",
        "        plt.setp(ax.get_xticklabels(), rotation=xticks_rotation)\n",
        "\n",
        "        self.figure_ = fig\n",
        "        self.ax_ = ax\n",
        "        return self\n",
        "\n",
        "    @classmethod\n",
        "    def from_estimator(\n",
        "        cls,\n",
        "        estimator,\n",
        "        X,\n",
        "        y,\n",
        "        *,\n",
        "        labels=None,\n",
        "        sample_weight=None,\n",
        "        normalize=None,\n",
        "        display_labels=None,\n",
        "        include_values=True,\n",
        "        xticks_rotation=\"horizontal\",\n",
        "        values_format=None,\n",
        "        cmap=\"Blues\",\n",
        "        ax=None,\n",
        "        colorbar=True,\n",
        "    ):\n",
        "        \n",
        "        method_name = f\"{cls.__name__}.from_estimator\"\n",
        "        \n",
        "        if not is_classifier(estimator):\n",
        "            raise ValueError(f\"{method_name} only supports classifiers\")\n",
        "        y_pred = estimator.predict(X)\n",
        "\n",
        "        return cls.from_predictions(\n",
        "            y,\n",
        "            y_pred,\n",
        "            sample_weight=sample_weight,\n",
        "            labels=labels,\n",
        "            normalize=normalize,\n",
        "            display_labels=display_labels,\n",
        "            include_values=include_values,\n",
        "            cmap=cmap,\n",
        "            ax=ax,\n",
        "            xticks_rotation=xticks_rotation,\n",
        "            values_format=values_format,\n",
        "            colorbar=colorbar,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def from_predictions(\n",
        "        cls,\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        *,\n",
        "        labels=None,\n",
        "        sample_weight=None,\n",
        "        normalize=None,\n",
        "        display_labels=None,\n",
        "        include_values=True,\n",
        "        xticks_rotation=\"horizontal\",\n",
        "        values_format=None,\n",
        "        cmap=\"Blues\",\n",
        "        ax=None,\n",
        "        colorbar=True,\n",
        "    ):\n",
        "\n",
        "        check_matplotlib_support(f\"{cls.__name__}.from_predictions\")\n",
        "\n",
        "        if display_labels is None:\n",
        "            if labels is None:\n",
        "                display_labels = unique_labels(y_true, y_pred)\n",
        "            else:\n",
        "                display_labels = labels\n",
        "\n",
        "        cm = confusion_matrix(\n",
        "            y_true,\n",
        "            y_pred,\n",
        "            sample_weight=sample_weight,\n",
        "            labels=labels,\n",
        "            normalize=normalize,\n",
        "        )\n",
        "\n",
        "        disp = cls(confusion_matrix=cm, display_labels=display_labels)\n",
        "\n",
        "        return disp.plot(\n",
        "            include_values=include_values,\n",
        "            cmap=cmap,\n",
        "            ax=ax,\n",
        "            xticks_rotation=xticks_rotation,\n",
        "            values_format=values_format,\n",
        "            colorbar=colorbar,\n",
        "        )\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_edit(estimator, X, y_true, *, labels=None,\n",
        "                          sample_weight=None, normalize=None,\n",
        "                          display_labels=None, include_values=True,\n",
        "                          xticks_rotation='horizontal',\n",
        "                          values_format=None,\n",
        "                          cmap='Blues', ax=None, colorbar=True):\n",
        "\n",
        "    y_pred = estimator.predict(X)\n",
        "    cm = confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n",
        "                          labels=labels, normalize=normalize)\n",
        "\n",
        "    if display_labels is None:\n",
        "        if labels is None:\n",
        "            display_labels = unique_labels(y_true, y_pred)\n",
        "        else:\n",
        "            display_labels = labels\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                  display_labels=display_labels)\n",
        "    return disp.plot(include_values=include_values,\n",
        "                     cmap=cmap, ax=ax, xticks_rotation=xticks_rotation,\n",
        "                     values_format=values_format, colorbar=colorbar)"
      ],
      "metadata": {
        "id": "J-otEnavjto_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/trabalho IA/covid_2022_prepared.csv\", sep=';')"
      ],
      "metadata": {
        "id": "YXJ-APXIlTop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratios(y):\n",
        "    \"\"\"\n",
        "        y: y_train ou y_test\n",
        "        retorna total e porcentagens\n",
        "    \"\"\"\n",
        "    \n",
        "    df1 = y.value_counts().rename_axis('OBITO').reset_index(name='Total')\n",
        "    df2 = (y.value_counts(normalize=True)*100).rename_axis('OBITO').reset_index(name='Porcentagem').drop(columns='OBITO')\n",
        "    df_concat = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "    return df_concat\n",
        "    "
      ],
      "metadata": {
        "id": "Grw0chQ_liVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = df.drop(['EVOLUCAO'], axis=1)\n",
        "y_ = df['EVOLUCAO']"
      ],
      "metadata": {
        "id": "DVtKY1oqmTNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validacao\n",
        "X, X_test_, y, y_test_ = train_test_split(X_, y_, stratify=y_, test_size=0.3, random_state=777)"
      ],
      "metadata": {
        "id": "wowN4PGemU7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "v6qmCPQ8mYBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "sycBSbUJmZW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratios(y)"
      ],
      "metadata": {
        "id": "z5hgiPcFmaeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratios(y_test_)"
      ],
      "metadata": {
        "id": "u6gZdpNhmd0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve, roc_curve, auc\n",
        "\n",
        "\n",
        "# balanceamento\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline \n",
        "from statistics import mean, stdev\n",
        "from collections import Counter\n",
        "\n",
        "def print_metric(results, name):\n",
        "    media = np.mean(results)\n",
        "    desvio_padrao = np.std(results)\n",
        "    print(f\"{name} \", end='')\n",
        "    print(\"médio: %.3f | intervalo: [%.3f, %.3f]\" % ((media), (media - 2 * desvio_padrao), (media + 2 * desvio_padrao)))"
      ],
      "metadata": {
        "id": "jHon9e8HpPTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial parameters\n",
        "SEED = 777\n",
        "K_FOLD = 5\n",
        "\n",
        "models = [RandomForestClassifier(random_state=SEED)]\n",
        "verbose_models = ['Random Forest Classifier']\n",
        "\n",
        "\n",
        "#undersampler\n",
        "rus = RandomUnderSampler(random_state=SEED)\n",
        "\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "for name, model in zip(verbose_models, models):\n",
        "    print(\"===============\")\n",
        "    print(name + \" - ORIGINAL\")\n",
        "    \n",
        "    auc_roc = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1score = []\n",
        "    aucscore = []\n",
        "    # kfold\n",
        "    kf = StratifiedKFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # percorre cada fold      \n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        # divisao treino e teste\n",
        "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # treino e predicao\n",
        "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "        # computacao da metrica\n",
        "        auc_roc.append(roc_auc_score(y_test, y_pred))\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=2)\n",
        "        aucscore.append(auc(fpr, tpr))\n",
        "        precision.append(precision_score(y_test, y_pred))\n",
        "        recall.append(recall_score(y_test, y_pred))\n",
        "        f1score.append(f1_score(y_test, y_pred))\n",
        "        \n",
        "\n",
        "    print_metric(auc_roc, 'AUC-ROC')\n",
        "    print_metric(precision, 'PRECISÃO')\n",
        "    print_metric(recall, 'REVOCAÇÃO')\n",
        "    print_metric(f1score, 'F1 SCORE')\n",
        "    print_metric(aucscore, 'AUC')\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # MATRIZ DE CONFUSAO\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "    #fig, ax2 = plt.subplots(figsize=(10, 10))\n",
        "    \n",
        "    #plot_confusion_matrix_edit(model, X_test_, y_test_, values_format= '.2%', normalize='true', \n",
        "      #                display_labels=['Recuperado', 'Óbito'], ax=ax1, colorbar=False); \n",
        "\n",
        "    print(\"===============\")\n",
        "\n",
        "    auc_roc = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1score = []\n",
        "    aucscore = []\n",
        "\n",
        "    # kfold\n",
        "    kf = StratifiedKFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
        "\n",
        "    print(name + \" - BALANCEADO\")\n",
        "    \n",
        "    # pipeline do modelo\n",
        "    pipeline = make_pipeline(rus, model)\n",
        "    \n",
        "    for train_index, test_index in kf.split(X,y):\n",
        "        # divisao treino e teste\n",
        "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # treino e predicao\n",
        "        y_pred = pipeline.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "        # computacao da metrica\n",
        "        auc_roc.append(roc_auc_score(y_test, y_pred))\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=2)\n",
        "        aucscore.append(auc(fpr, tpr))\n",
        "        \n",
        "        precision.append(precision_score(y_test, y_pred))\n",
        "        recall.append(recall_score(y_test, y_pred))\n",
        "        f1score.append(f1_score(y_test, y_pred))\n",
        "\n",
        "    print_metric(auc_roc, 'AUC-ROC')\n",
        "    print_metric(precision, 'PRECISÃO')\n",
        "    print_metric(recall, 'REVOCAÇÃO')\n",
        "    print_metric(f1score, 'F1 SCORE')\n",
        "    print_metric(aucscore, 'AUC')\n",
        "    print(confusion_matrix(y_test, y_pred))  \n",
        "\n",
        "    plot_confusion_matrix_edit(model, X_test_, y_test_,\n",
        "                      display_labels=['Recuperado', 'Óbito'], ax=ax1, colorbar=True);\n",
        "\n",
        "    plot_confusion_matrix_edit(model, X_test_, y_test_, values_format= '.2%', normalize='true',\n",
        "                      display_labels=['Recuperado', 'Óbito'], ax=ax2, colorbar=True); \n",
        "\n",
        "    #ax2.title.set_text(f\"Matriz de confusão - {name} \\nSubamostragem\")\n",
        "    plt.tight_layout()\n",
        "    plt.show() \n",
        "\n",
        "    print(\"===============\")"
      ],
      "metadata": {
        "id": "LpTo3gRypdR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}